{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import pandas as pd\n",
    "def quick_analysis(df):\n",
    " print(“Data Types:”)\n",
    " print(df.dtypes)\n",
    " print(“Rows and Columns:”)\n",
    " print(df.shape)\n",
    " print(“Column Names:”)\n",
    " print(df.columns)\n",
    " print(“Null Values:”)\n",
    " print(df.apply(lambda x: sum(x.isnull()) / len(df)))\n",
    "quick_analysis(train)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import matplotlib.pyplot as plt   #identifying variables types\n",
    "train[train.dtypes[(train.dtypes==\"float64\")|(train.dtypes==\"int64\")]\n",
    "                        .index.values].hist(figsize=[11,11])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''dummy_cols = ['thal', 'chest_pain_type', 'num_major_vessels',     #dummy\n",
    "              'exercise_induced_angina', 'fasting_blood_sugar_gt_120_mg_per_dl', \n",
    "              'resting_ekg_results', 'slope_of_peak_exercise_st_segment']\n",
    "train = pd.get_dummies(train, columns = dummy_cols)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn import preprocessing    #scaling\n",
    "n_test = train[['serum_cholesterol_mg_per_dl','max_heart_rate_achieved',\n",
    "                'oldpeak_eq_st_depression', 'resting_blood_pressure']]\n",
    "cols_to_norm = ['serum_cholesterol_mg_per_dl','max_heart_rate_achieved',\n",
    "                'oldpeak_eq_st_depression', 'resting_blood_pressure']\n",
    "x = n_test.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "n_test = pd.DataFrame(x_scaled, columns=cols_to_norm)\n",
    "l_test = train.drop(['serum_cholesterol_mg_per_dl','max_heart_rate_achieved',\n",
    "                'oldpeak_eq_st_depression', 'resting_blood_pressure'], axis=1)\n",
    "train = pd.concat([n_test, l_test], axis=1)\n",
    "train.columns'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''bins = [30, 40, 50, 60, 70, 80]   #binning\n",
    "group_names = ['30-39', '40-49', '50-59', '60-69', '70-79']\n",
    "age_categories = pd.cut(train['age'], bins, labels=group_names)\n",
    "train['age_categories'] = pd.cut(train['age'], bins, labels=group_names)\n",
    "age_categories\n",
    "pd.value_counts(train['age_categories'])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter Notebook Data Visualization Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Jupyter Notebook Data Visualization Python_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# convert all Yes's to 1's and the No's to 0's\n",
    "recipes = recipes.replace(to_replace=\"Yes\", value=1)\n",
    "recipes = recipes.replace(to_replace=\"No\", value=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import decision trees scikit-learn libraries\n",
    "%matplotlib inline\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "!conda install python-graphviz --yes\n",
    "import graphviz\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select subset of cuisines\n",
    "asian_indian_recipes = recipes[recipes.cuisine.isin([\"korean\", \"japanese\", \"chinese\", \"thai\", \"indian\"])]\n",
    "cuisines = asian_indian_recipes[\"cuisine\"]\n",
    "ingredients = asian_indian_recipes.iloc[:,1:]\n",
    "\n",
    "bamboo_tree = tree.DecisionTreeClassifier(max_depth=3)\n",
    "bamboo_tree.fit(ingredients, cuisines)\n",
    "\n",
    "print(\"Decision tree model saved to bamboo_tree!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(bamboo_tree,\n",
    "                feature_names=list(ingredients.columns.values),\n",
    "                out_file=\"bamboo_tree.dot\",\n",
    "                class_names=np.unique(cuisines),\n",
    "                filled=True,\n",
    "                node_ids=True,\n",
    "                special_characters=True,\n",
    "                impurity=False,\n",
    "                label=\"all\",\n",
    "                leaves_parallel=False)\n",
    "\n",
    "with open(\"bamboo_tree.dot\") as bamboo_tree_image:\n",
    "    bamboo_tree_graph = bamboo_tree_image.read()\n",
    "graphviz.Source(bamboo_tree_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sample size\n",
    "sample_n = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take 30 recipes from each cuisine\n",
    "random.seed(1234) # set random seed\n",
    "bamboo_test = bamboo.groupby(\"cuisine\", group_keys=False).apply(lambda x: x.sample(sample_n))\n",
    "\n",
    "bamboo_test_ingredients = bamboo_test.iloc[:,1:] # ingredients\n",
    "bamboo_test_cuisines = bamboo_test[\"cuisine\"] # corresponding cuisines or labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cuisines = np.unique(bamboo_test_cuisines)\n",
    "bamboo_confusion_matrix = confusion_matrix(bamboo_test_cuisines, bamboo_pred_cuisines, test_cuisines)\n",
    "title = 'Bamboo Confusion Matrix'\n",
    "cmap = plt.cm.Blues\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "bamboo_confusion_matrix = (\n",
    "    bamboo_confusion_matrix.astype('float') / bamboo_confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "    ) * 100\n",
    "\n",
    "plt.imshow(bamboo_confusion_matrix, interpolation='nearest', cmap=cmap)\n",
    "plt.title(title)\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(test_cuisines))\n",
    "plt.xticks(tick_marks, test_cuisines)\n",
    "plt.yticks(tick_marks, test_cuisines)\n",
    "\n",
    "fmt = '.2f'\n",
    "thresh = bamboo_confusion_matrix.max() / 2.\n",
    "for i, j in itertools.product(range(bamboo_confusion_matrix.shape[0]), range(bamboo_confusion_matrix.shape[1])):\n",
    "    plt.text(j, i, format(bamboo_confusion_matrix[i, j], fmt),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if bamboo_confusion_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to predict outliers\n",
    "#1 boxplot\n",
    "#2 scatterplot\n",
    "#3 z score\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "z = np.abs(stats.zscore(boston_df))\n",
    "print(z)\n",
    "threshold = 3\n",
    "print(np.where(z > 3))\n",
    "#4 IQR\n",
    "Q1 = boston_df_o1.quantile(0.25)\n",
    "Q3 = boston_df_o1.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "print(boston_df_o1 < (Q1 - 1.5 * IQR)) |(boston_df_o1 > (Q3 + 1.5 * IQR))\n",
    "\n",
    "#remove outliers identified by zscore\n",
    "boston_df_o = boston_df_o[(z < 3).all(axis=1)]\n",
    "\n",
    "#IQR\n",
    "boston_df_out = boston_df_o1[~((boston_df_o1 < (Q1 - 1.5 * IQR)) |(boston_df_o1 > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "boston_df_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Author: Virgile Fritsch <virgile.fritsch@inria.fr>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Get data\n",
    "X1 = load_boston()['data'][:, [8, 10]]  # two clusters\n",
    "X2 = load_boston()['data'][:, [5, 12]]  # \"banana\"-shaped\n",
    "\n",
    "# Define \"classifiers\" to be used\n",
    "classifiers = {\n",
    "    \"Empirical Covariance\": EllipticEnvelope(support_fraction=1.,\n",
    "                                             contamination=0.261),\n",
    "    \"Robust Covariance (Minimum Covariance Determinant)\":\n",
    "    EllipticEnvelope(contamination=0.261),\n",
    "    \"OCSVM\": OneClassSVM(nu=0.261, gamma=0.05)}\n",
    "colors = ['m', 'g', 'b']\n",
    "legend1 = {}\n",
    "legend2 = {}\n",
    "\n",
    "# Learn a frontier for outlier detection with several classifiers\n",
    "xx1, yy1 = np.meshgrid(np.linspace(-8, 28, 500), np.linspace(3, 40, 500))\n",
    "xx2, yy2 = np.meshgrid(np.linspace(3, 10, 500), np.linspace(-5, 45, 500))\n",
    "for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    plt.figure(1)\n",
    "    clf.fit(X1)\n",
    "    Z1 = clf.decision_function(np.c_[xx1.ravel(), yy1.ravel()])\n",
    "    Z1 = Z1.reshape(xx1.shape)\n",
    "    legend1[clf_name] = plt.contour(\n",
    "        xx1, yy1, Z1, levels=[0], linewidths=2, colors=colors[i])\n",
    "    plt.figure(2)\n",
    "    clf.fit(X2)\n",
    "    Z2 = clf.decision_function(np.c_[xx2.ravel(), yy2.ravel()])\n",
    "    Z2 = Z2.reshape(xx2.shape)\n",
    "    legend2[clf_name] = plt.contour(\n",
    "        xx2, yy2, Z2, levels=[0], linewidths=2, colors=colors[i])\n",
    "\n",
    "legend1_values_list = list(legend1.values())\n",
    "legend1_keys_list = list(legend1.keys())\n",
    "\n",
    "# Plot the results (= shape of the data points cloud)\n",
    "plt.figure(1)  # two clusters\n",
    "plt.title(\"Outlier detection on a real data set (boston housing)\")\n",
    "plt.scatter(X1[:, 0], X1[:, 1], color='black')\n",
    "bbox_args = dict(boxstyle=\"round\", fc=\"0.8\")\n",
    "arrow_args = dict(arrowstyle=\"->\")\n",
    "plt.annotate(\"several confounded points\", xy=(24, 19),\n",
    "             xycoords=\"data\", textcoords=\"data\",\n",
    "             xytext=(13, 10), bbox=bbox_args, arrowprops=arrow_args)\n",
    "plt.xlim((xx1.min(), xx1.max()))\n",
    "plt.ylim((yy1.min(), yy1.max()))\n",
    "plt.legend((legend1_values_list[0].collections[0],\n",
    "            legend1_values_list[1].collections[0],\n",
    "            legend1_values_list[2].collections[0]),\n",
    "           (legend1_keys_list[0], legend1_keys_list[1], legend1_keys_list[2]),\n",
    "           loc=\"upper center\",\n",
    "           prop=matplotlib.font_manager.FontProperties(size=12))\n",
    "plt.ylabel(\"accessibility to radial highways\")\n",
    "plt.xlabel(\"pupil-teacher ratio by town\")\n",
    "\n",
    "legend2_values_list = list(legend2.values())\n",
    "legend2_keys_list = list(legend2.keys())\n",
    "\n",
    "plt.figure(2)  # \"banana\" shape\n",
    "plt.title(\"Outlier detection on a real data set (boston housing)\")\n",
    "plt.scatter(X2[:, 0], X2[:, 1], color='black')\n",
    "plt.xlim((xx2.min(), xx2.max()))\n",
    "plt.ylim((yy2.min(), yy2.max()))\n",
    "plt.legend((legend2_values_list[0].collections[0],\n",
    "            legend2_values_list[1].collections[0],\n",
    "            legend2_values_list[2].collections[0]),\n",
    "           (legend2_keys_list[0], legend2_keys_list[1], legend2_keys_list[2]),\n",
    "           loc=\"upper center\",\n",
    "           prop=matplotlib.font_manager.FontProperties(size=12))\n",
    "plt.ylabel(\"% lower status of the population\")\n",
    "plt.xlabel(\"average number of rooms per dwelling\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
